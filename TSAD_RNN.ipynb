{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TSAD-RNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN5ZDSKB22VcckK7ZRtSOCq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ynukou/AnomalyDetectionGANs/blob/main/TSAD_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rnQMl2DsDn-k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ada9e37-239b-4d1e-9221-280f7dd457af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/RNN-Time-series-Anomaly-Detection"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShQ_MN89S4VW",
        "outputId": "4f573627-875d-4c50-8212-e7d1a821d972"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/RNN-Time-series-Anomaly-Detection\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjSwR7n2S63_",
        "outputId": "5d5a09e7-2545-4cf9-b957-fb625045d1e0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0_download_dataset.py       anomalyDetector.py  png2gif.py          \u001b[0m\u001b[01;34mresult\u001b[0m/\n",
            "1_train_predictor_all.sh    \u001b[01;34mdataset\u001b[0m/            preprocess_data.py  \u001b[01;34msave\u001b[0m/\n",
            "1_train_predictor.py        \u001b[01;34mfig\u001b[0m/                \u001b[01;34m__pycache__\u001b[0m/\n",
            "2_anomaly_detection_all.sh  LICENSE             README.md\n",
            "2_anomaly_detection.py      \u001b[01;34mmodel\u001b[0m/              requirements.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cat README.md"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSJGMx0jrFrx",
        "outputId": "8130da6d-356f-44bc-c652-b23553268914"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# RNN-Time-series-Anomaly-Detection\n",
            "RNN based Time-series Anomaly detector model implemented in Pytorch.\n",
            "\n",
            "This is an implementation of RNN based time-series anomaly detector, which consists of two-stage strategy of time-series prediction and anomaly score calculation.\n",
            "\n",
            "\n",
            "## Requirements\n",
            "* Ubuntu 16.04+ (Errors reported on Windows 10. see [issue](https://github.com/chickenbestlover/RNN-Time-series-Anomaly-Detection/issues/6#issue-358550020). Suggesstions are welcomed.)\n",
            "* Python 3.5+\n",
            "* Pytorch 0.4.0+\n",
            "* Numpy\n",
            "* Matplotlib\n",
            "* Scikit-learn\n",
            "\n",
            "## Dataset\n",
            "__1. NYC taxi passenger count__\n",
            " * The New York City taxi passenger data stream, provided by the [New\n",
            "York City Transportation Authority](http://www.nyc.gov/html/tlc/html/about/trip_record_data.shtml )\n",
            " * preprocessed (aggregated at 30 min intervals) by Cui, Yuwei, et al. in [\"A comparative study of HTM and other neural network models for online sequence learning with streaming data.\" Neural Networks (IJCNN), 2016 International Joint Conference on. IEEE, 2016.](http://ieeexplore.ieee.org/abstract/document/7727380/)\n",
            "  , [code](https://github.com/numenta/htmresearch/tree/master/projects/sequence_prediction)\n",
            "\n",
            "__2. Electrocardiograms (ECGs)__\n",
            " * The ECG dataset containing a single anomaly corresponding to a pre-ventricular contraction\n",
            "\n",
            "__3. 2D gesture (video surveilance)__\n",
            " * X Y coordinate of hand gesture in a video\n",
            "\n",
            "__4. Respiration__\n",
            " * A patients respiration (measured by thorax extension, sampling rate 10Hz)\n",
            "\n",
            "__5. Space shuttle__\n",
            " * Space Shuttle Marotta Valve time-series\n",
            "\n",
            "__6. Power demand__\n",
            " * One years power demand at a Dutch research facility\n",
            "\n",
            "The Time-series 2~6 are provided by E. Keogh et al. in\n",
            "[\"HOT SAX: Efficiently Finding the Most Unusual Time Series Subsequence.\" In The Fifth IEEE International Conference on Data Mining. (2005)\n",
            "](http://ieeexplore.ieee.org/abstract/document/1565683/)\n",
            "  , [dataset](http://www.cs.ucr.edu/~eamonn/discords/)\n",
            "\n",
            "### **_DISCLAIMER_**: \n",
            "_<U>The labels provided on this repository are unofficial and have not been verified. Labels were unofficially created by non-experts (annotated without any domain knowledge of the dataset or access to out-of-band data that could confirm the labels) and may contain mislabeled points (both false negatives, and false posatives). \n",
            "We referred to other time-series anomaly detection papers using the datasets   ([Malhotra et al., 2015.](https://www.elen.ucl.ac.be/Proceedings/esann/esannpdf/es2015-56.pdf),\n",
            "[Malhotra et al., 2016.](https://arxiv.org/pdf/1607.00148.pdf)) \n",
            "and the author's dataset presentation slides to label anomaly points in this time series as accurately as possible. If you need accurate label information, you should refer to the official [dataset](http://www.cs.ucr.edu/~eamonn/discords/) [description](http://www.cs.ucr.edu/~eamonn/discords/ICDM05_discords.pdf) or contact the authors.</U>_\n",
            "\n",
            "## RNN-based Multi-Step Prediction Model\n",
            "__0. Architecture__\n",
            "\n",
            "![arch](./fig/arch.png)\n",
            "\n",
            "When the value of x_i is known from i=0 to i=t, the model recursively predicts the value of x_i from i=t+1 to i=T. In this figure, t=3, T=8. We first train this model with a trainset which contains no anomalies, then we use the trained model to detect anomalies in a testset, where anomalies are included. \n",
            "\n",
            "__1. How to train this model__\n",
            "\n",
            "Recursive multi-step prediction using RNNs is a rather difficult problem. As the prediction progresses, the prediction errors are accumulated and the predictions rapidly become inaccurate. To solve this problem, we need a model that is robust to input noise.\n",
            "\n",
            "![1steploss](./fig/1steploss.png)\n",
            "\n",
            "TODO\n",
            "\n",
            "![msteploss](./fig/msteploss.png)\n",
            "\n",
            "TODO\n",
            "\n",
            "![pfloss](./fig/pfloss.png)\n",
            "\n",
            "TODO\n",
            "\n",
            "\n",
            "## RNN-based Multi-Step Prediction Model\n",
            "\n",
            "TODO\n",
            "\n",
            "\n",
            "## Example of usage\n",
            "__0. Download the dataset:__\n",
            "Download the five kinds of multivariate time-series dataset\n",
            "(ecg, gesture,power_demand, respiration, space_shuttle),\n",
            "and Label all the abnormality points in the dataset.\n",
            "```\n",
            "    python 0_download_dataset.py\n",
            "```\n",
            "\n",
            "\n",
            "__1. Time-series prediction:__\n",
            "Train and save RNN based time-series prediction model on a single time-series trainset\n",
            "```\n",
            "    python 1_train_predictor.py --data ecg --filename chfdb_chf14_45590.pkl\n",
            "    python 1_train_predictor.py --data nyc_taxi --filename nyc_taxi.pkl\n",
            "```\n",
            "Train multiple models using bash script\n",
            "\n",
            "```\n",
            "    ./1_train_predictor_all.sh\n",
            "```\n",
            "\n",
            "__2. Anomaly detection:__\n",
            "Fit multivariate gaussian distribution and\n",
            "calculate anomaly scores on a single time-series testset\n",
            "```\n",
            "    python 2_anomaly_detection.py --data ecg --filename chfdb_chf14_45590.pkl --prediction_window 10\n",
            "    python 2_anomaly_detection.py --data nyc_taxi --filename nyc_taxi.pkl --prediction_window 10\n",
            "```\n",
            "Test multiple models using bash script\n",
            "```\n",
            "    ./2_anomaly_detection_all.sh\n",
            "```\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "## Result\n",
            "__1. Time-series prediction:__\n",
            "Predictions from the stacked RNN model\n",
            "\n",
            "![prediction1](./fig/prediction_nyc_taxi.gif)\n",
            "\n",
            "\n",
            "![prediction2](./fig/prediction_ecg.gif)\n",
            "\n",
            "__2. Anomaly detection:__\n",
            "\n",
            "Anomaly scores from the Multivariate Gaussian Distribution model\n",
            "\n",
            "![equation1](./fig/equation1.gif)\n",
            "\n",
            "* NYC taxi passenger count\n",
            "\n",
            "![scores1](./fig/scores_nyc_taxi.png)\n",
            "\n",
            "\n",
            "* Electrocardiograms (ECGs) (filename: chfdb_chf14_45590)\n",
            "\n",
            "\n",
            "\n",
            "![scores3](./fig/scores_ecg1.png)\n",
            "\n",
            "\n",
            "![scores4](./fig/scores_ecg2.png)\n",
            "\n",
            "## Evaluation\n",
            "\n",
            "Model performance was evaluated by comparing the model output with the pre-labeled ground-truth. Note that the labels are only used for model evaluation. The anomaly score threshold was increased from 0 to some maximum value to plot the change of precision, recall, and f1 score. Here we show only the results for the ECG dataset. Execute the code yourself and see more results.\n",
            "\n",
            "__1. Precision, recall, and F1 score:__\n",
            "\n",
            "* Electrocardiograms (ECGs) (filename: chfdb_chf14_45590)\n",
            "\n",
            "a. channel 0\n",
            "\n",
            "![f1ecg1](./fig/fig_f_beta_channel0.png)\n",
            "\n",
            "b. channel 1\n",
            "\n",
            "![f1ecg2](./fig/fig_f_beta_channel1.png)\n",
            "\n",
            "\n",
            "## Citations\n",
            "\n",
            "Please consider citing this project in your publications if it helps your research. The following is a BibTeX reference. The BibTeX entry requires the url LaTeX package.\n",
            "\n",
            "```\n",
            "@misc{park2018anomaly,\n",
            "author = {Park, Jinman},\n",
            "title = {{RNN based Time-series Anomaly Detector Model Implemented in Pytorch}},\n",
            "year = {2018},\n",
            "howpublished = {\\url{https://github.com/chickenbestlover/RNN-Time-series-Anomaly-Detection}},\n",
            "note = {Accessed: [Insert date here]}\n",
            "}\n",
            "```\n",
            "\n",
            "\n",
            "## References\n",
            "* [Keogh, Eamonn et al. \"HOT SAX: Efficiently Finding the Most Unusual Time Series Subsequence.\" In The Fifth IEEE International Conference on Data Mining. (2005)\n",
            "](http://ieeexplore.ieee.org/abstract/document/1565683/)\n",
            "\n",
            "* [Malhotra, Pankaj, et al. \"Long short term memory networks for anomaly detection in time series.\" Proceedings. Presses universitaires de Louvain, 2015.](https://www.elen.ucl.ac.be/Proceedings/esann/esannpdf/es2015-56.pdf)\n",
            "\n",
            "\n",
            "* [Malhotra, Pankaj, et al. \"LSTM-based encoder-decoder for multi-sensor anomaly detection.\" arXiv preprint arXiv:1607.00148 (2016).](https://arxiv.org/pdf/1607.00148.pdf)\n",
            "\n",
            "* [Park, Daehyung, Yuuna Hoshi, and Charles C. Kemp. \"A Multimodal Anomaly Detector for Robot-Assisted Feeding Using an LSTM-based Variational Autoencoder.\" IEEE Robotics and Automation Letters 3.3 (2018): 1544-1551.](https://arxiv.org/pdf/1711.00614.pdf)\n",
            "\n",
            "\n",
            "\n",
            "## Contact\n",
            "If you have any questions, please open an issue.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python 0_download_dataset.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5j7f85FTT9b",
        "outputId": "15f61ad8-5614-4581-f0a3-e38304371de5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://www.cs.ucr.edu/~eamonn/discords/ECG_data.zip\n",
            "Saving to dataset/ecg/raw/ECG_data.txt\n",
            "Extracting to dataset/ecg/raw/ECG_data.zip\n",
            "Downloading http://www.cs.ucr.edu/~eamonn/discords/mitdbx_mitdbx_108.txt\n",
            "Saving to dataset/ecg/raw/mitdbx_mitdbx_108.txt\n",
            "Downloading http://www.cs.ucr.edu/~eamonn/discords/qtdbsele0606.txt\n",
            "Saving to dataset/ecg/raw/qtdbsele0606.txt\n",
            "Downloading http://www.cs.ucr.edu/~eamonn/discords/chfdbchf15.txt\n",
            "Saving to dataset/ecg/raw/chfdbchf15.txt\n",
            "Downloading http://www.cs.ucr.edu/~eamonn/discords/qtdbsel102.txt\n",
            "Saving to dataset/ecg/raw/qtdbsel102.txt\n",
            "Downloading http://www.cs.ucr.edu/~eamonn/discords/ann_gun_CentroidA\n",
            "Saving to dataset/gesture/raw/ann_gun_CentroidA.txt\n",
            "Downloading http://www.cs.ucr.edu/~eamonn/discords/TEK16.txt\n",
            "Saving to dataset/space_shuttle/raw/TEK16.txt\n",
            "Downloading http://www.cs.ucr.edu/~eamonn/discords/TEK17.txt\n",
            "Saving to dataset/space_shuttle/raw/TEK17.txt\n",
            "Downloading http://www.cs.ucr.edu/~eamonn/discords/TEK14.txt\n",
            "Saving to dataset/space_shuttle/raw/TEK14.txt\n",
            "Downloading http://www.cs.ucr.edu/~eamonn/discords/nprs44.txt\n",
            "Saving to dataset/respiration/raw/nprs44.txt\n",
            "Downloading http://www.cs.ucr.edu/~eamonn/discords/nprs43.txt\n",
            "Saving to dataset/respiration/raw/nprs43.txt\n",
            "Downloading http://www.cs.ucr.edu/~eamonn/discords/power_data.txt\n",
            "Saving to dataset/power_demand/raw/power_data.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python 1_train_predictor.py --data nyc_taxi --filename nyc_taxi.pkl"
      ],
      "metadata": {
        "id": "sn2hzKLDevTR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af607d3d-eb6c-41d5-fc6f-071ba111fc4b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Start training from scratch\n",
            "-----------------------------------------------------------------------------------------\n",
            "Namespace(augment=True, batch_size=64, bptt=50, clip=10, data='nyc_taxi', device='cuda', dropout=0.2, emsize=32, epochs=100, eval_batch_size=64, filename='nyc_taxi.pkl', log_interval=10, lr=0.0002, model='LSTM', nhid=32, nlayers=2, prediction_window_size=10, pretrained=False, res_connection=False, resume=False, save_fig=False, save_interval=10, seed=1111, teacher_forcing_ratio=0.7, tied=False, weight_decay=0.0001)\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   1 |    10/   31 batches | ms/batch 54.7844 | loss  2.21 \n",
            "| epoch   1 |    20/   31 batches | ms/batch 49.3689 | loss  2.01 \n",
            "| epoch   1 |    30/   31 batches | ms/batch 48.8047 | loss  2.00 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   1 | time:  1.94s | valid loss 1.9104 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   2 |    10/   31 batches | ms/batch 54.5328 | loss  2.20 \n",
            "| epoch   2 |    20/   31 batches | ms/batch 86.4251 | loss  2.00 \n",
            "| epoch   2 |    30/   31 batches | ms/batch 91.7580 | loss  1.99 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   2 | time:  3.26s | valid loss 1.8958 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   3 |    10/   31 batches | ms/batch 58.4357 | loss  2.18 \n",
            "| epoch   3 |    20/   31 batches | ms/batch 47.9329 | loss  1.97 \n",
            "| epoch   3 |    30/   31 batches | ms/batch 48.1989 | loss  1.94 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   3 | time:  1.95s | valid loss 1.8273 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   4 |    10/   31 batches | ms/batch 53.1348 | loss  2.08 \n",
            "| epoch   4 |    20/   31 batches | ms/batch 47.0904 | loss  1.81 \n",
            "| epoch   4 |    30/   31 batches | ms/batch 47.8238 | loss  1.69 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   4 | time:  1.87s | valid loss 1.5491 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   5 |    10/   31 batches | ms/batch 52.2027 | loss  1.85 \n",
            "| epoch   5 |    20/   31 batches | ms/batch 47.6399 | loss  1.63 \n",
            "| epoch   5 |    30/   31 batches | ms/batch 49.5217 | loss  1.59 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   5 | time:  1.90s | valid loss 1.4463 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   6 |    10/   31 batches | ms/batch 52.5313 | loss  1.73 \n",
            "| epoch   6 |    20/   31 batches | ms/batch 47.7392 | loss  1.54 \n",
            "| epoch   6 |    30/   31 batches | ms/batch 47.3176 | loss  1.50 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   6 | time:  1.88s | valid loss 1.3475 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   7 |    10/   31 batches | ms/batch 51.3840 | loss  1.64 \n",
            "| epoch   7 |    20/   31 batches | ms/batch 47.9268 | loss  1.45 \n",
            "| epoch   7 |    30/   31 batches | ms/batch 47.4878 | loss  1.43 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   7 | time:  1.86s | valid loss 1.2547 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   8 |    10/   31 batches | ms/batch 52.7184 | loss  1.55 \n",
            "| epoch   8 |    20/   31 batches | ms/batch 47.1917 | loss  1.37 \n",
            "| epoch   8 |    30/   31 batches | ms/batch 48.7127 | loss  1.34 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   8 | time:  1.88s | valid loss 1.1647 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   9 |    10/   31 batches | ms/batch 53.0198 | loss  1.49 \n",
            "| epoch   9 |    20/   31 batches | ms/batch 47.5560 | loss  1.31 \n",
            "| epoch   9 |    30/   31 batches | ms/batch 49.8267 | loss  1.28 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   9 | time:  1.90s | valid loss 1.0011 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  10 |    10/   31 batches | ms/batch 52.2865 | loss  1.40 \n",
            "| epoch  10 |    20/   31 batches | ms/batch 46.0602 | loss  1.18 \n",
            "| epoch  10 |    30/   31 batches | ms/batch 48.1782 | loss  1.11 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  10 | time:  1.86s | valid loss 0.8346 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "=> saving checkpoint ..\n",
            "=> checkpoint saved.\n",
            "| epoch  11 |    10/   31 batches | ms/batch 52.9929 | loss  1.19 \n",
            "| epoch  11 |    20/   31 batches | ms/batch 47.1151 | loss  1.01 \n",
            "| epoch  11 |    30/   31 batches | ms/batch 48.7357 | loss  0.96 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  11 | time:  1.90s | valid loss 0.7380 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  12 |    10/   31 batches | ms/batch 52.2315 | loss  1.08 \n",
            "| epoch  12 |    20/   31 batches | ms/batch 47.9045 | loss  0.90 \n",
            "| epoch  12 |    30/   31 batches | ms/batch 47.7701 | loss  0.88 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  12 | time:  1.88s | valid loss 0.6459 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  13 |    10/   31 batches | ms/batch 51.7048 | loss  1.01 \n",
            "| epoch  13 |    20/   31 batches | ms/batch 48.9577 | loss  0.86 \n",
            "| epoch  13 |    30/   31 batches | ms/batch 48.0155 | loss  0.84 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  13 | time:  1.90s | valid loss 0.6128 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  14 |    10/   31 batches | ms/batch 53.2777 | loss  0.98 \n",
            "| epoch  14 |    20/   31 batches | ms/batch 48.3609 | loss  0.82 \n",
            "| epoch  14 |    30/   31 batches | ms/batch 48.1533 | loss  0.81 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  14 | time:  1.91s | valid loss 0.5705 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  15 |    10/   31 batches | ms/batch 53.0478 | loss  0.96 \n",
            "| epoch  15 |    20/   31 batches | ms/batch 51.1077 | loss  0.79 \n",
            "| epoch  15 |    30/   31 batches | ms/batch 47.8739 | loss  0.77 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  15 | time:  1.92s | valid loss 0.5448 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  16 |    10/   31 batches | ms/batch 55.6823 | loss  0.93 \n",
            "| epoch  16 |    20/   31 batches | ms/batch 47.9847 | loss  0.76 \n",
            "| epoch  16 |    30/   31 batches | ms/batch 49.1897 | loss  0.76 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  16 | time:  1.93s | valid loss 0.5239 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  17 |    10/   31 batches | ms/batch 53.0004 | loss  0.88 \n",
            "| epoch  17 |    20/   31 batches | ms/batch 48.9784 | loss  0.73 \n",
            "| epoch  17 |    30/   31 batches | ms/batch 51.0915 | loss  0.72 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  17 | time:  1.93s | valid loss 0.5003 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  18 |    10/   31 batches | ms/batch 53.8488 | loss  0.88 \n",
            "| epoch  18 |    20/   31 batches | ms/batch 47.4140 | loss  0.73 \n",
            "| epoch  18 |    30/   31 batches | ms/batch 47.4018 | loss  0.71 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  18 | time:  1.88s | valid loss 0.4825 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  19 |    10/   31 batches | ms/batch 54.2764 | loss  0.86 \n",
            "| epoch  19 |    20/   31 batches | ms/batch 47.8158 | loss  0.70 \n",
            "| epoch  19 |    30/   31 batches | ms/batch 47.9253 | loss  0.69 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  19 | time:  1.90s | valid loss 0.4683 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  20 |    10/   31 batches | ms/batch 53.1889 | loss  0.85 \n",
            "| epoch  20 |    20/   31 batches | ms/batch 49.3281 | loss  0.69 \n",
            "| epoch  20 |    30/   31 batches | ms/batch 47.2292 | loss  0.68 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  20 | time:  1.91s | valid loss 0.4370 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "=> saving checkpoint ..\n",
            "=> checkpoint saved.\n",
            "| epoch  21 |    10/   31 batches | ms/batch 52.4863 | loss  0.83 \n",
            "| epoch  21 |    20/   31 batches | ms/batch 51.7238 | loss  0.66 \n",
            "| epoch  21 |    30/   31 batches | ms/batch 47.4691 | loss  0.65 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  21 | time:  1.92s | valid loss 0.4175 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  22 |    10/   31 batches | ms/batch 53.5877 | loss  0.82 \n",
            "| epoch  22 |    20/   31 batches | ms/batch 48.4147 | loss  0.65 \n",
            "| epoch  22 |    30/   31 batches | ms/batch 47.4528 | loss  0.63 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  22 | time:  1.90s | valid loss 0.3839 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  23 |    10/   31 batches | ms/batch 51.9675 | loss  0.79 \n",
            "| epoch  23 |    20/   31 batches | ms/batch 48.2125 | loss  0.63 \n",
            "| epoch  23 |    30/   31 batches | ms/batch 48.3269 | loss  0.62 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  23 | time:  1.89s | valid loss 0.3781 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  24 |    10/   31 batches | ms/batch 54.5072 | loss  0.78 \n",
            "| epoch  24 |    20/   31 batches | ms/batch 49.2803 | loss  0.61 \n",
            "| epoch  24 |    30/   31 batches | ms/batch 50.1546 | loss  0.59 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  24 | time:  1.94s | valid loss 0.3610 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  25 |    10/   31 batches | ms/batch 55.0968 | loss  0.76 \n",
            "| epoch  25 |    20/   31 batches | ms/batch 48.0044 | loss  0.60 \n",
            "| epoch  25 |    30/   31 batches | ms/batch 48.9859 | loss  0.57 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  25 | time:  1.92s | valid loss 0.3160 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  26 |    10/   31 batches | ms/batch 54.0594 | loss  0.73 \n",
            "| epoch  26 |    20/   31 batches | ms/batch 48.2339 | loss  0.58 \n",
            "| epoch  26 |    30/   31 batches | ms/batch 49.7867 | loss  0.55 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  26 | time:  1.93s | valid loss 0.3286 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  27 |    10/   31 batches | ms/batch 53.6934 | loss  0.73 \n",
            "| epoch  27 |    20/   31 batches | ms/batch 48.5640 | loss  0.55 \n",
            "| epoch  27 |    30/   31 batches | ms/batch 49.4179 | loss  0.54 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  27 | time:  1.91s | valid loss 0.2941 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  28 |    10/   31 batches | ms/batch 52.9906 | loss  0.70 \n",
            "| epoch  28 |    20/   31 batches | ms/batch 47.7042 | loss  0.54 \n",
            "| epoch  28 |    30/   31 batches | ms/batch 47.5567 | loss  0.52 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  28 | time:  1.89s | valid loss 0.2965 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  29 |    10/   31 batches | ms/batch 53.6307 | loss  0.69 \n",
            "| epoch  29 |    20/   31 batches | ms/batch 48.2555 | loss  0.53 \n",
            "| epoch  29 |    30/   31 batches | ms/batch 81.4625 | loss  0.51 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  29 | time:  2.50s | valid loss 0.2783 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  30 |    10/   31 batches | ms/batch 53.0103 | loss  0.68 \n",
            "| epoch  30 |    20/   31 batches | ms/batch 46.8598 | loss  0.52 \n",
            "| epoch  30 |    30/   31 batches | ms/batch 48.1097 | loss  0.50 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  30 | time:  1.87s | valid loss 0.2579 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "=> saving checkpoint ..\n",
            "=> checkpoint saved.\n",
            "| epoch  31 |    10/   31 batches | ms/batch 53.4446 | loss  0.65 \n",
            "| epoch  31 |    20/   31 batches | ms/batch 48.5253 | loss  0.50 \n",
            "| epoch  31 |    30/   31 batches | ms/batch 48.5996 | loss  0.49 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  31 | time:  1.93s | valid loss 0.2984 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  32 |    10/   31 batches | ms/batch 55.3379 | loss  0.64 \n",
            "| epoch  32 |    20/   31 batches | ms/batch 49.2008 | loss  0.49 \n",
            "| epoch  32 |    30/   31 batches | ms/batch 48.9344 | loss  0.49 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  32 | time:  1.94s | valid loss 0.2464 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  33 |    10/   31 batches | ms/batch 53.9575 | loss  0.62 \n",
            "| epoch  33 |    20/   31 batches | ms/batch 47.8369 | loss  0.48 \n",
            "| epoch  33 |    30/   31 batches | ms/batch 47.1387 | loss  0.49 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  33 | time:  1.90s | valid loss 0.2387 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  34 |    10/   31 batches | ms/batch 52.3540 | loss  0.65 \n",
            "| epoch  34 |    20/   31 batches | ms/batch 48.2380 | loss  0.49 \n",
            "| epoch  34 |    30/   31 batches | ms/batch 46.8122 | loss  0.46 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  34 | time:  1.88s | valid loss 0.2414 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  35 |    10/   31 batches | ms/batch 53.2192 | loss  0.60 \n",
            "| epoch  35 |    20/   31 batches | ms/batch 49.9747 | loss  0.49 \n",
            "| epoch  35 |    30/   31 batches | ms/batch 49.0048 | loss  0.50 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  35 | time:  1.94s | valid loss 0.2557 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  36 |    10/   31 batches | ms/batch 54.3543 | loss  0.62 \n",
            "| epoch  36 |    20/   31 batches | ms/batch 48.2483 | loss  0.47 \n",
            "| epoch  36 |    30/   31 batches | ms/batch 48.0683 | loss  0.46 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  36 | time:  1.91s | valid loss 0.2277 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  37 |    10/   31 batches | ms/batch 53.3096 | loss  0.60 \n",
            "| epoch  37 |    20/   31 batches | ms/batch 47.8880 | loss  0.46 \n",
            "| epoch  37 |    30/   31 batches | ms/batch 49.0422 | loss  0.44 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  37 | time:  1.89s | valid loss 0.2194 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  38 |    10/   31 batches | ms/batch 55.2283 | loss  0.59 \n",
            "| epoch  38 |    20/   31 batches | ms/batch 47.3899 | loss  0.46 \n",
            "| epoch  38 |    30/   31 batches | ms/batch 48.5106 | loss  0.45 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  38 | time:  1.91s | valid loss 0.2226 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  39 |    10/   31 batches | ms/batch 53.3177 | loss  0.58 \n",
            "| epoch  39 |    20/   31 batches | ms/batch 48.0714 | loss  0.45 \n",
            "| epoch  39 |    30/   31 batches | ms/batch 48.3773 | loss  0.43 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  39 | time:  1.89s | valid loss 0.2285 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  40 |    10/   31 batches | ms/batch 53.6551 | loss  0.59 \n",
            "| epoch  40 |    20/   31 batches | ms/batch 47.3940 | loss  0.46 \n",
            "| epoch  40 |    30/   31 batches | ms/batch 49.9229 | loss  0.44 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  40 | time:  1.91s | valid loss 0.2277 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "=> saving checkpoint ..\n",
            "=> checkpoint saved.\n",
            "| epoch  41 |    10/   31 batches | ms/batch 52.3897 | loss  0.58 \n",
            "| epoch  41 |    20/   31 batches | ms/batch 47.8387 | loss  0.44 \n",
            "| epoch  41 |    30/   31 batches | ms/batch 47.6920 | loss  0.43 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  41 | time:  1.89s | valid loss 0.2178 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  42 |    10/   31 batches | ms/batch 53.4664 | loss  0.57 \n",
            "| epoch  42 |    20/   31 batches | ms/batch 48.6999 | loss  0.43 \n",
            "| epoch  42 |    30/   31 batches | ms/batch 47.1157 | loss  0.41 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  42 | time:  1.90s | valid loss 0.2037 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  43 |    10/   31 batches | ms/batch 51.7117 | loss  0.54 \n",
            "| epoch  43 |    20/   31 batches | ms/batch 47.7543 | loss  0.42 \n",
            "| epoch  43 |    30/   31 batches | ms/batch 48.0075 | loss  0.42 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  43 | time:  1.89s | valid loss 0.2122 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  44 |    10/   31 batches | ms/batch 52.1029 | loss  0.56 \n",
            "| epoch  44 |    20/   31 batches | ms/batch 48.8881 | loss  0.42 \n",
            "| epoch  44 |    30/   31 batches | ms/batch 48.3393 | loss  0.42 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  44 | time:  1.89s | valid loss 0.1957 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  45 |    10/   31 batches | ms/batch 53.1883 | loss  0.56 \n",
            "| epoch  45 |    20/   31 batches | ms/batch 47.6803 | loss  0.41 \n",
            "| epoch  45 |    30/   31 batches | ms/batch 49.2520 | loss  0.41 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  45 | time:  1.91s | valid loss 0.1968 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  46 |    10/   31 batches | ms/batch 53.9992 | loss  0.55 \n",
            "| epoch  46 |    20/   31 batches | ms/batch 48.1678 | loss  0.42 \n",
            "| epoch  46 |    30/   31 batches | ms/batch 49.2073 | loss  0.41 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  46 | time:  1.91s | valid loss 0.1935 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  47 |    10/   31 batches | ms/batch 52.9597 | loss  0.54 \n",
            "| epoch  47 |    20/   31 batches | ms/batch 46.9174 | loss  0.41 \n",
            "| epoch  47 |    30/   31 batches | ms/batch 49.3651 | loss  0.41 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  47 | time:  1.89s | valid loss 0.1890 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  48 |    10/   31 batches | ms/batch 55.0426 | loss  0.54 \n",
            "| epoch  48 |    20/   31 batches | ms/batch 47.4935 | loss  0.41 \n",
            "| epoch  48 |    30/   31 batches | ms/batch 49.0301 | loss  0.40 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  48 | time:  1.93s | valid loss 0.1865 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  49 |    10/   31 batches | ms/batch 53.9067 | loss  0.54 \n",
            "| epoch  49 |    20/   31 batches | ms/batch 48.8230 | loss  0.40 \n",
            "| epoch  49 |    30/   31 batches | ms/batch 49.6335 | loss  0.39 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  49 | time:  1.95s | valid loss 0.1854 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  50 |    10/   31 batches | ms/batch 53.3204 | loss  0.52 \n",
            "| epoch  50 |    20/   31 batches | ms/batch 48.6379 | loss  0.41 \n",
            "| epoch  50 |    30/   31 batches | ms/batch 47.4212 | loss  0.39 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  50 | time:  1.90s | valid loss 0.1815 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "=> saving checkpoint ..\n",
            "=> checkpoint saved.\n",
            "| epoch  51 |    10/   31 batches | ms/batch 52.2903 | loss  0.53 \n",
            "| epoch  51 |    20/   31 batches | ms/batch 50.7068 | loss  0.40 \n",
            "| epoch  51 |    30/   31 batches | ms/batch 47.9388 | loss  0.38 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  51 | time:  1.91s | valid loss 0.1859 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  52 |    10/   31 batches | ms/batch 53.6847 | loss  0.53 \n",
            "| epoch  52 |    20/   31 batches | ms/batch 48.4560 | loss  0.40 \n",
            "| epoch  52 |    30/   31 batches | ms/batch 49.1705 | loss  0.38 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  52 | time:  1.91s | valid loss 0.1871 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  53 |    10/   31 batches | ms/batch 54.3712 | loss  0.52 \n",
            "| epoch  53 |    20/   31 batches | ms/batch 46.8765 | loss  0.40 \n",
            "| epoch  53 |    30/   31 batches | ms/batch 48.9628 | loss  0.37 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  53 | time:  1.89s | valid loss 0.1757 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  54 |    10/   31 batches | ms/batch 53.2034 | loss  0.52 \n",
            "| epoch  54 |    20/   31 batches | ms/batch 46.9198 | loss  0.38 \n",
            "| epoch  54 |    30/   31 batches | ms/batch 48.7292 | loss  0.37 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  54 | time:  1.88s | valid loss 0.1746 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  55 |    10/   31 batches | ms/batch 53.7258 | loss  0.51 \n",
            "| epoch  55 |    20/   31 batches | ms/batch 47.5498 | loss  0.38 \n",
            "| epoch  55 |    30/   31 batches | ms/batch 49.5451 | loss  0.38 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  55 | time:  1.91s | valid loss 0.1781 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  56 |    10/   31 batches | ms/batch 53.9897 | loss  0.52 \n",
            "| epoch  56 |    20/   31 batches | ms/batch 47.4346 | loss  0.37 \n",
            "| epoch  56 |    30/   31 batches | ms/batch 47.3204 | loss  0.37 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  56 | time:  1.89s | valid loss 0.1691 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  57 |    10/   31 batches | ms/batch 52.3517 | loss  0.50 \n",
            "| epoch  57 |    20/   31 batches | ms/batch 49.9302 | loss  0.38 \n",
            "| epoch  57 |    30/   31 batches | ms/batch 49.2695 | loss  0.36 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  57 | time:  1.93s | valid loss 0.1672 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  58 |    10/   31 batches | ms/batch 52.5476 | loss  0.50 \n",
            "| epoch  58 |    20/   31 batches | ms/batch 47.8598 | loss  0.37 \n",
            "| epoch  58 |    30/   31 batches | ms/batch 49.4069 | loss  0.36 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  58 | time:  1.93s | valid loss 0.1647 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  59 |    10/   31 batches | ms/batch 53.3191 | loss  0.49 \n",
            "| epoch  59 |    20/   31 batches | ms/batch 48.9768 | loss  0.37 \n",
            "| epoch  59 |    30/   31 batches | ms/batch 48.1484 | loss  0.36 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  59 | time:  1.91s | valid loss 0.1670 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  60 |    10/   31 batches | ms/batch 52.4121 | loss  0.50 \n",
            "| epoch  60 |    20/   31 batches | ms/batch 48.9827 | loss  0.39 \n",
            "| epoch  60 |    30/   31 batches | ms/batch 48.8252 | loss  0.36 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  60 | time:  1.92s | valid loss 0.1703 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "=> saving checkpoint ..\n",
            "=> checkpoint saved.\n",
            "| epoch  61 |    10/   31 batches | ms/batch 53.1609 | loss  0.49 \n",
            "| epoch  61 |    20/   31 batches | ms/batch 47.0334 | loss  0.38 \n",
            "| epoch  61 |    30/   31 batches | ms/batch 50.4842 | loss  0.35 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  61 | time:  1.91s | valid loss 0.1768 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  62 |    10/   31 batches | ms/batch 53.1649 | loss  0.49 \n",
            "| epoch  62 |    20/   31 batches | ms/batch 47.5479 | loss  0.37 \n",
            "| epoch  62 |    30/   31 batches | ms/batch 50.0751 | loss  0.35 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  62 | time:  1.92s | valid loss 0.1675 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  63 |    10/   31 batches | ms/batch 54.3972 | loss  0.50 \n",
            "| epoch  63 |    20/   31 batches | ms/batch 46.7403 | loss  0.36 \n",
            "| epoch  63 |    30/   31 batches | ms/batch 50.6189 | loss  0.36 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  63 | time:  1.93s | valid loss 0.1731 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  64 |    10/   31 batches | ms/batch 57.9258 | loss  0.49 \n",
            "| epoch  64 |    20/   31 batches | ms/batch 47.7982 | loss  0.36 \n",
            "| epoch  64 |    30/   31 batches | ms/batch 49.6104 | loss  0.35 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  64 | time:  1.95s | valid loss 0.1570 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  65 |    10/   31 batches | ms/batch 54.6870 | loss  0.47 \n",
            "| epoch  65 |    20/   31 batches | ms/batch 48.0695 | loss  0.35 \n",
            "| epoch  65 |    30/   31 batches | ms/batch 49.0568 | loss  0.34 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  65 | time:  1.92s | valid loss 0.1561 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  66 |    10/   31 batches | ms/batch 54.9308 | loss  0.48 \n",
            "| epoch  66 |    20/   31 batches | ms/batch 49.1902 | loss  0.36 \n",
            "| epoch  66 |    30/   31 batches | ms/batch 48.8981 | loss  0.34 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  66 | time:  1.94s | valid loss 0.1539 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  67 |    10/   31 batches | ms/batch 53.7167 | loss  0.47 \n",
            "| epoch  67 |    20/   31 batches | ms/batch 48.6341 | loss  0.35 \n",
            "| epoch  67 |    30/   31 batches | ms/batch 47.9365 | loss  0.34 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  67 | time:  1.91s | valid loss 0.1634 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  68 |    10/   31 batches | ms/batch 52.6999 | loss  0.47 \n",
            "| epoch  68 |    20/   31 batches | ms/batch 49.1478 | loss  0.35 \n",
            "| epoch  68 |    30/   31 batches | ms/batch 47.7836 | loss  0.33 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  68 | time:  1.91s | valid loss 0.1507 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  69 |    10/   31 batches | ms/batch 53.4284 | loss  0.46 \n",
            "| epoch  69 |    20/   31 batches | ms/batch 50.4915 | loss  0.35 \n",
            "| epoch  69 |    30/   31 batches | ms/batch 48.5951 | loss  0.33 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  69 | time:  1.94s | valid loss 0.1515 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  70 |    10/   31 batches | ms/batch 53.8994 | loss  0.46 \n",
            "| epoch  70 |    20/   31 batches | ms/batch 48.7740 | loss  0.34 \n",
            "| epoch  70 |    30/   31 batches | ms/batch 49.5219 | loss  0.34 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  70 | time:  1.93s | valid loss 0.1520 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "=> saving checkpoint ..\n",
            "=> checkpoint saved.\n",
            "| epoch  71 |    10/   31 batches | ms/batch 54.3442 | loss  0.47 \n",
            "| epoch  71 |    20/   31 batches | ms/batch 47.6045 | loss  0.34 \n",
            "| epoch  71 |    30/   31 batches | ms/batch 49.2021 | loss  0.33 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  71 | time:  1.93s | valid loss 0.1509 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  72 |    10/   31 batches | ms/batch 54.0369 | loss  0.46 \n",
            "| epoch  72 |    20/   31 batches | ms/batch 48.6718 | loss  0.34 \n",
            "| epoch  72 |    30/   31 batches | ms/batch 48.8738 | loss  0.33 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  72 | time:  1.91s | valid loss 0.1464 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  73 |    10/   31 batches | ms/batch 53.6414 | loss  0.46 \n",
            "| epoch  73 |    20/   31 batches | ms/batch 48.5888 | loss  0.34 \n",
            "| epoch  73 |    30/   31 batches | ms/batch 48.7032 | loss  0.33 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  73 | time:  1.92s | valid loss 0.1458 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  74 |    10/   31 batches | ms/batch 54.8889 | loss  0.45 \n",
            "| epoch  74 |    20/   31 batches | ms/batch 48.3786 | loss  0.34 \n",
            "| epoch  74 |    30/   31 batches | ms/batch 49.2952 | loss  0.33 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  74 | time:  1.93s | valid loss 0.1471 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  75 |    10/   31 batches | ms/batch 53.6633 | loss  0.45 \n",
            "| epoch  75 |    20/   31 batches | ms/batch 49.3792 | loss  0.33 \n",
            "| epoch  75 |    30/   31 batches | ms/batch 47.6991 | loss  0.33 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  75 | time:  1.92s | valid loss 0.1441 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  76 |    10/   31 batches | ms/batch 53.3759 | loss  0.45 \n",
            "| epoch  76 |    20/   31 batches | ms/batch 49.5684 | loss  0.33 \n",
            "| epoch  76 |    30/   31 batches | ms/batch 48.1119 | loss  0.31 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  76 | time:  1.92s | valid loss 0.1426 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  77 |    10/   31 batches | ms/batch 53.5928 | loss  0.45 \n",
            "| epoch  77 |    20/   31 batches | ms/batch 51.1871 | loss  0.33 \n",
            "| epoch  77 |    30/   31 batches | ms/batch 47.9238 | loss  0.32 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  77 | time:  1.94s | valid loss 0.1435 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  78 |    10/   31 batches | ms/batch 54.1659 | loss  0.45 \n",
            "| epoch  78 |    20/   31 batches | ms/batch 48.9076 | loss  0.33 \n",
            "| epoch  78 |    30/   31 batches | ms/batch 47.0492 | loss  0.32 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  78 | time:  1.90s | valid loss 0.1429 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  79 |    10/   31 batches | ms/batch 53.3573 | loss  0.44 \n",
            "| epoch  79 |    20/   31 batches | ms/batch 49.3043 | loss  0.32 \n",
            "| epoch  79 |    30/   31 batches | ms/batch 47.1037 | loss  0.32 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  79 | time:  1.91s | valid loss 0.1398 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  80 |    10/   31 batches | ms/batch 54.9812 | loss  0.44 \n",
            "| epoch  80 |    20/   31 batches | ms/batch 48.1125 | loss  0.33 \n",
            "| epoch  80 |    30/   31 batches | ms/batch 48.4635 | loss  0.31 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  80 | time:  1.92s | valid loss 0.1444 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "=> saving checkpoint ..\n",
            "=> checkpoint saved.\n",
            "| epoch  81 |    10/   31 batches | ms/batch 53.9734 | loss  0.44 \n",
            "| epoch  81 |    20/   31 batches | ms/batch 49.5504 | loss  0.32 \n",
            "| epoch  81 |    30/   31 batches | ms/batch 48.5032 | loss  0.31 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  81 | time:  1.97s | valid loss 0.1385 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  82 |    10/   31 batches | ms/batch 74.8154 | loss  0.43 \n",
            "| epoch  82 |    20/   31 batches | ms/batch 67.5575 | loss  0.33 \n",
            "| epoch  82 |    30/   31 batches | ms/batch 67.4559 | loss  0.31 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  82 | time:  2.68s | valid loss 0.1510 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  83 |    10/   31 batches | ms/batch 61.4095 | loss  0.44 \n",
            "| epoch  83 |    20/   31 batches | ms/batch 48.2320 | loss  0.33 \n",
            "| epoch  83 |    30/   31 batches | ms/batch 48.2026 | loss  0.31 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  83 | time:  1.98s | valid loss 0.1450 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  84 |    10/   31 batches | ms/batch 53.7988 | loss  0.44 \n",
            "| epoch  84 |    20/   31 batches | ms/batch 49.3440 | loss  0.32 \n",
            "| epoch  84 |    30/   31 batches | ms/batch 49.3128 | loss  0.31 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  84 | time:  1.94s | valid loss 0.1383 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  85 |    10/   31 batches | ms/batch 53.7590 | loss  0.44 \n",
            "| epoch  85 |    20/   31 batches | ms/batch 47.8996 | loss  0.32 \n",
            "| epoch  85 |    30/   31 batches | ms/batch 48.5522 | loss  0.30 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  85 | time:  1.92s | valid loss 0.1366 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  86 |    10/   31 batches | ms/batch 53.3849 | loss  0.43 \n",
            "| epoch  86 |    20/   31 batches | ms/batch 47.7227 | loss  0.31 \n",
            "| epoch  86 |    30/   31 batches | ms/batch 48.1014 | loss  0.31 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  86 | time:  1.89s | valid loss 0.1371 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  87 |    10/   31 batches | ms/batch 54.0119 | loss  0.43 \n",
            "| epoch  87 |    20/   31 batches | ms/batch 47.0559 | loss  0.32 \n",
            "| epoch  87 |    30/   31 batches | ms/batch 48.9057 | loss  0.31 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  87 | time:  1.89s | valid loss 0.1364 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  88 |    10/   31 batches | ms/batch 57.8944 | loss  0.43 \n",
            "| epoch  88 |    20/   31 batches | ms/batch 48.4820 | loss  0.31 \n",
            "| epoch  88 |    30/   31 batches | ms/batch 48.7504 | loss  0.30 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  88 | time:  1.95s | valid loss 0.1387 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  89 |    10/   31 batches | ms/batch 53.8236 | loss  0.43 \n",
            "| epoch  89 |    20/   31 batches | ms/batch 49.0793 | loss  0.31 \n",
            "| epoch  89 |    30/   31 batches | ms/batch 48.5521 | loss  0.31 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  89 | time:  1.91s | valid loss 0.1364 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  90 |    10/   31 batches | ms/batch 52.5053 | loss  0.43 \n",
            "| epoch  90 |    20/   31 batches | ms/batch 48.0275 | loss  0.31 \n",
            "| epoch  90 |    30/   31 batches | ms/batch 48.5320 | loss  0.30 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  90 | time:  1.90s | valid loss 0.1352 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "=> saving checkpoint ..\n",
            "=> checkpoint saved.\n",
            "| epoch  91 |    10/   31 batches | ms/batch 52.7252 | loss  0.43 \n",
            "| epoch  91 |    20/   31 batches | ms/batch 50.5449 | loss  0.31 \n",
            "| epoch  91 |    30/   31 batches | ms/batch 47.6090 | loss  0.30 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  91 | time:  1.92s | valid loss 0.1314 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  92 |    10/   31 batches | ms/batch 52.2478 | loss  0.42 \n",
            "| epoch  92 |    20/   31 batches | ms/batch 49.1061 | loss  0.31 \n",
            "| epoch  92 |    30/   31 batches | ms/batch 47.3577 | loss  0.29 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  92 | time:  1.89s | valid loss 0.1504 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  93 |    10/   31 batches | ms/batch 53.3680 | loss  0.43 \n",
            "| epoch  93 |    20/   31 batches | ms/batch 49.7230 | loss  0.31 \n",
            "| epoch  93 |    30/   31 batches | ms/batch 48.0803 | loss  0.29 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  93 | time:  1.92s | valid loss 0.1325 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  94 |    10/   31 batches | ms/batch 54.4556 | loss  0.42 \n",
            "| epoch  94 |    20/   31 batches | ms/batch 48.7563 | loss  0.30 \n",
            "| epoch  94 |    30/   31 batches | ms/batch 48.2838 | loss  0.30 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  94 | time:  1.91s | valid loss 0.1367 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  95 |    10/   31 batches | ms/batch 53.6233 | loss  0.42 \n",
            "| epoch  95 |    20/   31 batches | ms/batch 51.0952 | loss  0.30 \n",
            "| epoch  95 |    30/   31 batches | ms/batch 48.8862 | loss  0.29 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  95 | time:  1.93s | valid loss 0.1288 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  96 |    10/   31 batches | ms/batch 53.1485 | loss  0.42 \n",
            "| epoch  96 |    20/   31 batches | ms/batch 47.6795 | loss  0.30 \n",
            "| epoch  96 |    30/   31 batches | ms/batch 48.8780 | loss  0.29 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  96 | time:  1.90s | valid loss 0.1364 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  97 |    10/   31 batches | ms/batch 52.9589 | loss  0.42 \n",
            "| epoch  97 |    20/   31 batches | ms/batch 47.6790 | loss  0.30 \n",
            "| epoch  97 |    30/   31 batches | ms/batch 48.4275 | loss  0.29 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  97 | time:  1.89s | valid loss 0.1289 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  98 |    10/   31 batches | ms/batch 53.6650 | loss  0.41 \n",
            "| epoch  98 |    20/   31 batches | ms/batch 46.8617 | loss  0.31 \n",
            "| epoch  98 |    30/   31 batches | ms/batch 47.9860 | loss  0.29 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  98 | time:  1.90s | valid loss 0.1297 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  99 |    10/   31 batches | ms/batch 53.6096 | loss  0.41 \n",
            "| epoch  99 |    20/   31 batches | ms/batch 48.5703 | loss  0.29 \n",
            "| epoch  99 |    30/   31 batches | ms/batch 47.1524 | loss  0.28 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  99 | time:  1.91s | valid loss 0.1271 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch 100 |    10/   31 batches | ms/batch 54.2632 | loss  0.41 \n",
            "| epoch 100 |    20/   31 batches | ms/batch 52.1050 | loss  0.30 \n",
            "| epoch 100 |    30/   31 batches | ms/batch 48.4057 | loss  0.29 \n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch 100 | time:  1.95s | valid loss 0.1244 | \n",
            "-----------------------------------------------------------------------------------------\n",
            "=> saving checkpoint ..\n",
            "=> checkpoint saved.\n",
            "=> calculating mean and covariance\n",
            "=> saving checkpoint ..\n",
            "=> checkpoint saved.\n",
            "-----------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python 2_anomaly_detection.py --data nyc_taxi --filename nyc_taxi.pkl --prediction_window 10"
      ],
      "metadata": {
        "id": "vXDu3fi2lYbk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "304240c5-6bb8-4be2-bcc9-84ed58e5570f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------------------------------\n",
            "=> loading checkpoint \n",
            "=> loaded checkpoint\n",
            "=> loading pre-calculated mean and covariance\n",
            "=> calculating anomaly scores\n",
            "=> calculating precision, recall, and f_beta\n",
            "/content/drive/MyDrive/RNN-Time-series-Anomaly-Detection/anomalyDetector.py:107: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  th = torch.logspace(0, torch.log10(torch.tensor(maximum)), num_samples).to(args.device)\n",
            "data:  nyc_taxi  filename:  nyc_taxi.pkl  f-beta (no compensation):  0.048654619604349136  beta:  1.0\n",
            "=> loading pre-calculated mean and covariance\n",
            "=> calculating anomaly scores\n",
            "=> calculating precision, recall, and f_beta\n",
            "data:  nyc_taxi  filename:  nyc_taxi.pkl  f-beta (no compensation):  0.040492944419384  beta:  1.0\n",
            "=> loading pre-calculated mean and covariance\n",
            "=> calculating anomaly scores\n",
            "=> calculating precision, recall, and f_beta\n",
            "data:  nyc_taxi  filename:  nyc_taxi.pkl  f-beta (no compensation):  0.07185624539852142  beta:  1.0\n",
            "=> saving the results as pickle extensions\n",
            "-----------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}